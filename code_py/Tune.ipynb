{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lisker2/CS309_Project/blob/main/code_py/Tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nadavbra/shared_utils.git\n",
        "!git clone https://github.com/nadavbra/protein_bert\n",
        "!git clone https://github.com/khanhlee/bert-enhancer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOn3RzoQ0XLk",
        "outputId": "bcb4017a-86a8-4543-e495-6d8dd9aa31fe"
      },
      "id": "IOn3RzoQ0XLk",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'shared_utils'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 48 (delta 26), reused 37 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (48/48), 22.66 KiB | 800.00 KiB/s, done.\n",
            "Cloning into 'protein_bert'...\n",
            "remote: Enumerating objects: 206, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 206 (delta 52), reused 66 (delta 40), pack-reused 121\u001b[K\n",
            "Receiving objects: 100% (206/206), 23.43 MiB | 29.99 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n",
            "Cloning into 'bert-enhancer'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 90 (delta 35), reused 90 (delta 35), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (90/90), 1.04 MiB | 5.89 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first install python 3.6\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.6\n",
        "# change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 1\n",
        "# select python version\n",
        "!sudo update-alternatives --config python3\n",
        "# check python version\n",
        "!python --version\n",
        "# install pip for new python \n",
        "!sudo apt-get install python3.6-distutils\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python get-pip.py\n",
        "# upgrade pip\n",
        "!sudo apt install python3-pip\n",
        "!python -m pip install --upgrade pip\n",
        "!python3.6 -m pip install tensorflow==2.4.0\n",
        "!python3.6 -m pip install protein-bert\n",
        "!python3.6 -m pip install matplotlib\n",
        "!python3.6 -m pip  install scikit-learn\n",
        "!python3.6 -m pip  install numpy\n",
        "!python3.6 -m pip  install pandas\n",
        "!python3.6 -m pip  install scipy\n",
        "!python3.6 -m pip  install ipykernel"
      ],
      "metadata": {
        "id": "lqZulh3z0ufA"
      },
      "id": "lqZulh3z0ufA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0ec919e5",
      "metadata": {
        "id": "0ec919e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e6949b8-dacb-4360-e560-2aacd3ef686a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-04 23:50:17.294415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "sequence_length 202\n",
            "[2023_05_04-23:50:20] Training set: Filtered out 0 of 2768 (0.0%) records of lengths exceeding 200.\n",
            "[2023_05_04-23:50:20] Validation set: Filtered out 0 of 300 (0.0%) records of lengths exceeding 200.\n",
            "[2023_05_04-23:50:20] Training with frozen pretrained layers...\n",
            "2023-05-04 23:50:21.018646: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2023-05-04 23:50:21.019129: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-05-04 23:50:21.019195: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2023-05-04 23:50:21.019250: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6249d7089d30): /proc/driver/nvidia/version does not exist\n",
            "2023-05-04 23:50:21.022409: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2023-05-04 23:50:23.091470: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2023-05-04 23:50:23.092726: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
            "Epoch 1/40\n",
            "87/87 [==============================] - 21s 141ms/step - loss: 0.8621 - val_loss: 0.5243\n",
            "Epoch 2/40\n",
            "87/87 [==============================] - 10s 114ms/step - loss: 0.5745 - val_loss: 0.5298\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "Epoch 3/40\n",
            "87/87 [==============================] - 10s 116ms/step - loss: 0.5927 - val_loss: 0.5200\n",
            "Epoch 4/40\n",
            "87/87 [==============================] - 10s 111ms/step - loss: 0.5841 - val_loss: 0.5256\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "Epoch 5/40\n",
            "87/87 [==============================] - 10s 114ms/step - loss: 0.5419 - val_loss: 0.5158\n",
            "Epoch 6/40\n",
            "87/87 [==============================] - 10s 112ms/step - loss: 0.5326 - val_loss: 0.5282\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "Epoch 7/40\n",
            "87/87 [==============================] - 10s 113ms/step - loss: 0.5565 - val_loss: 0.5145\n",
            "Epoch 8/40\n",
            "87/87 [==============================] - 9s 108ms/step - loss: 0.5556 - val_loss: 0.5155\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
            "Epoch 9/40\n",
            "87/87 [==============================] - 10s 115ms/step - loss: 0.5436 - val_loss: 0.5144\n",
            "Epoch 10/40\n",
            "87/87 [==============================] - 10s 111ms/step - loss: 0.5521 - val_loss: 0.5145\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 11/40\n",
            "87/87 [==============================] - 9s 109ms/step - loss: 0.5319 - val_loss: 0.5145\n",
            "[2023_05_04-23:52:21] Training the entire fine-tuned model...\n",
            "[2023_05_04-23:52:31] Incompatible number of optimizer weights - will not initialize them.\n",
            "Epoch 1/40\n",
            "87/87 [==============================] - 37s 342ms/step - loss: 0.5437 - val_loss: 0.5155\n",
            "Epoch 2/40\n",
            "87/87 [==============================] - 26s 298ms/step - loss: 0.5340 - val_loss: 0.5359\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "Epoch 3/40\n",
            "87/87 [==============================] - 26s 293ms/step - loss: 0.5285 - val_loss: 0.5116\n",
            "Epoch 4/40\n",
            "87/87 [==============================] - 25s 290ms/step - loss: 0.5182 - val_loss: 0.5096\n",
            "Epoch 5/40\n",
            "87/87 [==============================] - 26s 294ms/step - loss: 0.5196 - val_loss: 0.5250\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 6/40\n",
            "87/87 [==============================] - 25s 289ms/step - loss: 0.5218 - val_loss: 0.5083\n",
            "Epoch 7/40\n",
            "87/87 [==============================] - 25s 292ms/step - loss: 0.5158 - val_loss: 0.5087\n",
            "Epoch 8/40\n",
            "87/87 [==============================] - 25s 286ms/step - loss: 0.5114 - val_loss: 0.5090\n",
            "[2023_05_04-23:56:06] Training on final epochs of sequence length 1024...\n",
            "[2023_05_04-23:56:06] Training set: Filtered out 0 of 2768 (0.0%) records of lengths exceeding 1022.\n",
            "[2023_05_04-23:56:06] Validation set: Filtered out 0 of 300 (0.0%) records of lengths exceeding 1022.\n",
            "462/462 [==============================] - 137s 283ms/step - loss: 0.5304 - val_loss: 0.5163\n",
            "Test-set performance:\n",
            "               # records       AUC\n",
            "Model seq len                     \n",
            "202                  300  0.849111\n",
            "All                  300  0.849111\n",
            "Confusion matrix:\n",
            "     0    1\n",
            "0  122   28\n",
            "1   35  115\n",
            "GGCAGAGGTTGCCGTGAGCCGAGATTGCGCCATTGCACTCCAGCCTGAGCAACAAGAGTGAAACTCTGTCTCAAAAAAAAAAAAAAAAAAAAATTTGGCTGGGGGCGGTGGCTCATGCCTGTAATCCCAGCACTTTGGGAGGCTAAAGCAGGTGGATCACCTGAGGTCAGTTCGAGACCAGCCTGGCCAATATGGTGAAA 0\n"
          ]
        }
      ],
      "source": [
        "!python3.6 tune.py"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}