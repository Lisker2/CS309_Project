{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyNgLQP1aCX0QaoojlZPXct/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lisker2/CS309_Project/blob/main/gene_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbwrHFFDTPGz"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/nadavbra/shared_utils.git\n",
        "!pip install protein-bert"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
        "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
        "from proteinbert import load_pretrained_model"
      ],
      "metadata": {
        "id": "Jq29Oi0SBBVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model_generator, input_encoder = load_pretrained_model(\"/content/\")"
      ],
      "metadata": {
        "id": "GHgjfk4JAvAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('protein_benchmarks/stability.train.csv')[:2000]\n",
        "valid = pd.read_csv('protein_benchmarks/stability.valid.csv')[:300]\n",
        "test = pd.read_csv('protein_benchmarks/stability.test.csv')[:2000]\n",
        "\n",
        "train_X = train['seq']\n",
        "valid_X = valid['seq']\n",
        "test_X = test['seq']\n",
        "train_Y = train['label']\n",
        "valid_Y = valid['label']\n",
        "test_Y = test['label']\n",
        "print(train)\n",
        "sequence_length = max(train.seq.map(lambda x: len(x)).max(), \n",
        "             test.seq.map(lambda x: len(x)).max(), \n",
        "             valid.seq.map(lambda x: len(x)).max()) + 2\n",
        "print('sequence_length', sequence_length)\n",
        "\n",
        "train_X = input_encoder.encode_X(train_X, sequence_length)\n",
        "valid_X = input_encoder.encode_X(valid_X, sequence_length)\n",
        "test_X = input_encoder.encode_X(test_X, sequence_length)"
      ],
      "metadata": {
        "id": "5MwLcKvlC2FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_generator = get_model_with_hidden_layers_as_outputs(pretrained_model_generator.create_model(sequence_length))"
      ],
      "metadata": {
        "id": "AyottQ1QF_dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_representations_train, global_representations_train= model_generator.predict(train_X, batch_size = 64)\n",
        "local_representations_test, global_representations_test= model_generator.predict(test_X, batch_size = 64)\n"
      ],
      "metadata": {
        "id": "cAPqfLdDGD23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(global_representations_train)"
      ],
      "metadata": {
        "id": "ZJmy55Q-HUBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_stability = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape = local_representations_train[0].shape),\n",
        "    tf.keras.layers.Dense(1, activation = 'softmax'),\n",
        "]\n",
        ")\n",
        "model_stability.compile(loss='mse',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['mse'])\n",
        "\n",
        "training_callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(patience = 30, factor = 0.1, min_lr = 0.0001, verbose = 1),\n",
        "    tf.keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
        "]\n",
        "history_stability = model_stability.fit(local_representations_train, train_Y,\n",
        "                                batch_size=64, epochs=30,\n",
        "                                callbacks=training_callbacks)\n",
        "     "
      ],
      "metadata": {
        "id": "kXlAvCJvJZnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history_stability.history['loss']\n",
        "plt.plot(range(len(loss)), loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "MhkwudohKb6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_Y = model_stability.predict(local_representations_test)\n",
        "print(predict_Y)\n",
        "p, _ = spearmanr(predict_Y, test_Y)\n",
        "print(p)"
      ],
      "metadata": {
        "id": "3kcFfpl7Moaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "cf9twukjxVbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_cv = pd.read_csv('non.cv.txt')[::2]\n",
        "non_cv.columns = ['seq']\n",
        "print(len(non_cv))\n",
        "\n",
        "label_1 = [0 for i in range(len(non_cv['seq']))]\n",
        "non_cv['label'] = label_1\n",
        "\n",
        "enhancer_cv = pd.read_csv('enhancer.cv.txt')[::2]\n",
        "\n",
        "enhancer_cv.columns = ['seq']\n",
        "print((len(enhancer_cv)))\n",
        "label_1 = [1 for i in range(len(enhancer_cv))]\n",
        "enhancer_cv['label'] = label_1"
      ],
      "metadata": {
        "id": "PZC6G3cRw2rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enhancer_train = pd.concat([non_cv, enhancer_cv],axis=0)\n",
        "enhancer_train.index = range(len(enhancer_train))\n",
        "enhancer_train.head()"
      ],
      "metadata": {
        "id": "3Y-M0-EgzUBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_ind = pd.read_csv('non.ind.txt')[::2]\n",
        "non_ind.columns = ['seq']\n",
        "print((len(non_ind)))\n",
        "\n",
        "label_1 = [0 for i in range(len(non_ind))]\n",
        "non_ind['label'] = label_1\n",
        "\n",
        "enhancer_ind = pd.read_csv('enhancer.ind.txt')[::2]\n",
        "enhancer_ind.columns = ['seq']\n",
        "print((len(enhancer_ind)))\n",
        "\n",
        "label_1 = [1 for i in range(len(enhancer_ind))]\n",
        "enhancer_ind['label'] = label_1"
      ],
      "metadata": {
        "id": "JCulkDbhy30L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "cn1I3dHLSRGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enhancer_test = pd.concat([non_ind, enhancer_ind],axis=0)\n",
        "enhancer_test.index = range(len(enhancer_test))\n",
        "enhancer_test.head()"
      ],
      "metadata": {
        "id": "H2ACFriSgLxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enhancer_valid=enhancer_train.sample(n=None, frac=0.1, replace=False, weights=None, random_state=None, axis=0)"
      ],
      "metadata": {
        "id": "akZuWkLabCdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = enhancer_train['seq']\n",
        "test_X = enhancer_test['seq']\n",
        "valid_X= enhancer_valid['seq']\n",
        "train_Y = enhancer_train['label']\n",
        "test_Y = enhancer_test['label']\n",
        "valid_Y= enhancer_valid['label']\n",
        "sequence_length = max(enhancer_train.seq.map(lambda x: len(x)).max(), \n",
        "             enhancer_test.seq.map(lambda x: len(x)).max(),\n",
        "             enhancer_valid.seq.map(lambda x: len(x)).max())+2\n",
        "print('sequence_length', sequence_length)"
      ],
      "metadata": {
        "id": "lGQdrgCH0PYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = input_encoder.encode_X(train_X, sequence_length)\n",
        "test_X = input_encoder.encode_X(test_X, sequence_length)\n",
        "valid_X= input_encoder.encode_X(valid_X, sequence_length)"
      ],
      "metadata": {
        "id": "BjyzYbLiq4cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_generator = get_model_with_hidden_layers_as_outputs(pretrained_model_generator.create_model(sequence_length))"
      ],
      "metadata": {
        "id": "5IjNeDyL1SOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_representations_train, global_representations_train= model_generator.predict(train_X, batch_size = 64)\n",
        "local_representations_test, global_representations_test= model_generator.predict(test_X, batch_size = 64)\n",
        "local_representations_valid, global_representations_valid= model_generator.predict(valid_X, batch_size = 64)"
      ],
      "metadata": {
        "id": "cKn91j9cc1Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_stability = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, 3, activation='relu',input_shape=(202,1562,1)),\n",
        "    tf.keras.layers.MaxPooling2D((2)),\n",
        "    tf.keras.layers.Conv2D(64, 3, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation = 'sigmoid'),\n",
        "    tf.keras.layers.Dense(64, activation = 'linear'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model_stability.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['binary_accuracy'])\n",
        "\n",
        "training_callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(patience = 5, factor = 0.2, min_lr = 0.001, verbose = 1),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='binary_accuracy',patience = 3, restore_best_weights = True, verbose=1),\n",
        "]\n",
        "\n",
        "history_stability = model_stability.fit(local_representations_train, train_Y,\n",
        "                                validation_data=(local_representations_valid, valid_Y),\n",
        "                                batch_size=32, epochs=50,callbacks=training_callbacks)\n",
        "     "
      ],
      "metadata": {
        "id": "oB2kUPTmc--C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_Y = model_stability.predict(local_representations_test)\n",
        "p, _ = spearmanr(predict_Y, test_Y)\n",
        "print(p)"
      ],
      "metadata": {
        "id": "waPkw5KIlPHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history_stability.history['binary_accuracy']\n",
        "plt.plot(range(len(loss)), loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "3bDF9_S4npc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_Y=model_stability.predict(local_representations_test)\n",
        "\n",
        "for i in range(len(predict_Y)):\n",
        "  if(predict_Y[i]>0.5):\n",
        "    predict_Y[i]=1\n",
        "  else:\n",
        "    predict_Y[i]=0\n",
        "error=0\n",
        "test_Y=np.array(test_Y)\n",
        "for i in range(len(predict_Y)):\n",
        "  error+=abs(predict_Y[i]-test_Y[i])\n",
        "print(1-error/len(predict_Y))"
      ],
      "metadata": {
        "id": "agIGQNZAmWgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc(predict_Y,test_Y):\n",
        "  for i in range(len(predict_Y)):\n",
        "    if(predict_Y[i]>0.5):\n",
        "      predict_Y[i]=1\n",
        "    else:\n",
        "      predict_Y[i]=0\n",
        "  error=0\n",
        "  test_Y=np.array(test_Y)\n",
        "  for i in range(len(predict_Y)):\n",
        "    error+=abs(predict_Y[i]-test_Y[i])\n",
        "  return(1-error/len(predict_Y))\n"
      ],
      "metadata": {
        "id": "W95_PNFF2NC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils import shuffle\n",
        "cross_data=shuffle(enhancer_train).reset_index(drop=True)\n",
        "cross_data_X=cross_data['seq']\n",
        "cross_data_Y=cross_data['label']\n",
        "kf=KFold(n_splits=6)\n",
        "kf.get_n_splits(cross_data_X)\n",
        "KFold(n_splits=6, random_state=None, shuffle=False)\n",
        "\n",
        "\n",
        "     \n",
        "for i, (train_index,test_index) in enumerate(kf.split(cross_data_X)):\n",
        "  train_X=cross_data_X[train_index]\n",
        "  test_X=cross_data_X[test_index]\n",
        "  train_Y = cross_data_Y[train_index]\n",
        "  test_Y=cross_data_Y[test_index]\n",
        "\n",
        "  train_X = input_encoder.encode_X(train_X, sequence_length)\n",
        "  test_X= input_encoder.encode_X(test_X, sequence_length)\n",
        "  \n",
        "  local_representations_train, global_representations_train= model_generator.predict(train_X, batch_size = 64)\n",
        "  local_representations_test, global_representations_test= model_generator.predict(test_X, batch_size = 64)\n",
        "  \n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  model_stability = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, 3, activation='relu',input_shape=(202,1562,1)),\n",
        "      tf.keras.layers.MaxPooling2D((2)),\n",
        "      tf.keras.layers.Conv2D(64, 3, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D((2)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation = 'sigmoid'),\n",
        "      tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "  ])\n",
        "  model_stability.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['binary_accuracy'])\n",
        "  \n",
        "  history_stability = model_stability.fit(local_representations_train, train_Y,\n",
        "                                batch_size=32, epochs=20)\n",
        "\n",
        "  predict_Y=model_stability.predict(local_representations_test)\n",
        "  print(calc(predict_Y,test_Y)) \n",
        "\n",
        "  if(i==0):\n",
        "    model_stability.save(\"my_model\")\n",
        "  if(i==1):\n",
        "    model_stability.save(\"my_mode2\")\n",
        "  if(i==2):\n",
        "    model_stability.save(\"my_mode3\")\n",
        "  if(i==3):\n",
        "    model_stability.save(\"my_mode4\")\n",
        "  if(i==4):\n",
        "    model_stability.save(\"my_mode5\")\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "loss = history_stability.history['binary_accuracy']\n",
        "plt.plot(range(len(loss)), loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "k4xtzymEoLIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_model = keras.models.load_model(\"my_mode2\")\n",
        "predict_Y=reconstructed_model.predict(local_representations_test)\n",
        "print(test_Y)\n",
        "print(len(predict_Y))\n",
        "print(calc(predict_Y,test_Y)) \n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "tBwHDg2d4QIJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}